reference https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection.git
 #  概念

 - 目标检测
 - SSD：single-shot detection
 早期的目标检测包括两个阶段：区域建议网络（进行目标定位）、分类器（检测建议区域中的目标类别）。从计算角度看，是相当耗时，且并不适用于实际场景的实时应用。SSD模型将定位和检测任务封装进一个单一的前项网络中，从而使得当部署在轻量化的硬件时，能够进行更快的检测
 
 - 多尺度特征图
 在图像分类任务中，预测是基于最终的卷积特征图-原始图像最小但最深的表示。在目标检测中，从中间卷积层中得到的特征图也是能够直接使用的，因为这些是原始图像上不同尺度的变现。因此一个固定尺寸的滤波器在不同特征图上进行卷积，能够检测不同大小的目标
 
 - 先验
 在特定特征图上的特定位置上定义的预计算的框boxes，即为先验。这些boxes有特定的横纵比和尺度（尺寸）。这些是通过仔细选择得到的，以便能够匹配数据集中目标bbox（ground-truth）的性质
 
 - multibox
 这是一个技巧，其将目标bbox的预测作为一个回归问题进行处理。其中被检测到的目标的坐标与其真值坐标进行回归。再有，对于每个预测到的box，为不同的类别是生成不同的得分。先验（上述）作为预测阶段的初始点，因为先验是在真值上建模得到的。因此一共有和先验一样多的预测框box，其中的大部分是不包含目标的。
其预测分为两个部分：1）包含或不包含目标的box的坐标，这是一个胡桂任务；2）这个box的对于不同目标类别的得分，包括背景（表示box中没有背景类），这是一个分类任务
 
 - hard negative mining
 没翻译
 
 - NMS非极大值抑制
 在任何一个给定的位置，多个先验可能重叠。因此产生于这些先验得到预测box可能实际上是同一个目标的重叠box，NMS就是通过抑制除了最大得分的那个box的剩下的所有box来去除冗余的预测

#  overview

 - 边界坐标
 - 中心坐标
 - IOU
 - multibox
 见上面
 
 - SSD
 SSD是一个全卷积网络，主要包含三个部分
 1）基础卷积：由存在的图像分类框架得到，主要提供低层次的特征图
 2）辅助卷积：连接在基础网络的顶部，提供高层次的特征图
 3）预测卷积：在这些特征图中定位和识别
 文章提出了两个模型SSD300和SSD512，数字表示的身世输入图像的尺寸。
##  基础卷积-part1
作者使用的是VGG16框架作为基础网络。文章建议使用在ILSVRC分类任务上预训练的模型。**其在pytorch中已经有实现**，选择其他的也行，但是要考虑计算量的需求。

该git-tutorial中，在预训练的网络中做作出了一些改变，来适应自己的目标检测任务。这些是出于逻辑性和必要性考虑的，以及一些方便性和偏好性。

 - 输入图像尺寸：300*300
 - 第3个poolinglayer，即进行维度减半的操作，使用的是ceil（向上取整）机制而取代默认的floor（向下）取整机制，来决定输出的尺寸。只要前面的特征图是奇数而不是偶数，那么就是有意义的。
 - 改进第5个poolinglayer，从原有的2*2kernel,2stride，编程3*3kernel,1stride。这使得对特征图不在进行维度减半操作
 - 并不需要全连接层（即分类），抛弃fc8，并将fc6和fc7变成全卷积层conv6和conv7

fc到卷积的变换
**值得注意的是当RGB拉伸变成1D时，组织顺序如git上所示，要特别看一下**

**这里可能要注意，虽然是一个2D卷积核，一般在定义的时候只定义不同卷积核的个数，单个卷积核的通道数自动与输入的特征图的通道相同，但是该卷积核的不同通道数上的参数都是不一样的**

##  基础卷积-part2
**这里关于改进的部分没看懂...???...**
常规操作就是讲原来的全连接层转换为全卷积层，
但是转换的卷积核个数太多且大，及其消耗计算
为了改善这个问题，原文作者选择减少卷积核的数量和尺寸，即通过对参数进行子采样...???...这点没懂见; （'github原文'）
github文档中使用了一种像素的方法，但是没懂...???...
针对卷积核尺寸不一的问题，使用的是膨胀卷积的方法。


##  辅助卷积
在上述基础网络行堆叠更多的卷积层。这些卷积层提供额外的特征图，且尺寸逐渐减小。
一共引进了4个卷积block，每个bock包含2层。尽管在基础网路中，利用pooling层尺寸已经减少，在辅助卷积中的每个block中的第2层都使用stride=2的卷积核操作。

##  a detour
在进行预测卷积之前，必须理解要预测的东西是什么。就是目标及其位置，但是目标和位置都是以什么形式存在的呢？
这里必须了解先验priors及其在SSD中扮演的关键角色

###  priors先验
目标检测是相当复杂的，不仅仅值得是其种类。目标可以出现在人任何位置，具有任意的尺寸和形状。（值得注意的是，这里并不打算阐述目标出现在哪里和以怎样形式出现的无线可能性。虽然从数学角度上式可能的，但是许多选择是不可能的或无趣的。...???...）

**实际上，可以将可能的预测的数学空间离散成数千种可能**
**先验priors是预先进行计算的，且具有固定大小的boxes，后面这句话怎么翻译...???...**
**先验框是手动的，但是认真选择的，其基于数据集中真值目标的尺寸和形状来选择的。通过将这些先验框放在一个特征图中的每个可能位置，且考虑了位置上的变化。**

**原作者对先验框的定义如下：**
 - 这些先验框被应用到各种高层和低层次特征图上，也就是来自conv4_3,conv7,conv8_2,conv9_2,conv10_2,conv11_2的特征图。
 - 如果一个先验框有一个尺度s（用来根据面积和后续定义的横纵比，来计算具体的先验框的大小），那么其面积等于边长为s的正方形，最大的特征图即conv4_3，其对应的先验框的尺度为0.1，即图像维度的10%，而剩下的先验框的尺度（对应的是不同特征图（来自于不同的层）下）从0.2线性增加到0.9（0.2；0.375；0.55；0.725；0.9）。可以看出，更大的特征图具有更小尺度的先验框，因此能够更好的检测小目标
 - 在一个特征图上每个位置，其具有不同横纵比的先验框。所有的特征图中的先验框的横纵比为1:1、2:1、1:2。而中间的特征图conv7,conv8_2,conv9_2还具有横纵比为3:1、1:3的先验框。再有所有的特征图，都具有一个额外的先验框，该先验框的横纵比为1:1，尺度为当前特征图和后面一个特征图的尺度的几何平均值。（这里有一个问题，最后一个特征图没有后续特征图，怎么计算尺度的几何平均...???...）
 - **见github中的表格**

###  先验框的可视化
